{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATEN√á√ÉO\n",
    "Caro corretor, eu me chamo Ester Quintino e estou realizando o meu projeto com o Rodrigo Gatti,sob autoriza√ß√£o do  professor F√°bio Miranda.No in√≠cio, eu fazia dupla com o Pedro Santos. Entretanto, n√£o deu para continuar, e eu passei a fazer dupla com o Rodrigo . Inicialmente, nosso (meu e do Rodrigo) era \"trident\", mas devido a erros q encontramos ao decorrer do desenvolvimento do trabalho, tivemos que mudar o produto e mudamos para \"Doritos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 13/Set at√© √†s 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "At√© o dia 06 de Setembro √†s 23:59, o notebook e o xlsx devem estar no Github com as seguintes evid√™ncias: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste j√° classificado.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conex√£o com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que ser√£o utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados √© necess√°rio ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda n√£o tenha uma: https://twitter.com/signup\n",
    "1. Depois √© necess√°rio registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote tamb√©m:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATEN√á√ÉO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele cont√©m as chaves necess√°rias para realizar as opera√ß√µes no twitter de forma autom√°tica e portanto √© equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as opera√ß√µes manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo n√£o precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @QuintinoEster\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, n√£o haver√° uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Doritos'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora voc√™ deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem √© relevante ou n√£o.<br /> \n",
    "N√£o se esque√ßa de colocar um nome para a coluna na c√©lula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu c√≥digo abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpmath import mpf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "import mpmath\n",
    "\n",
    "#dados_Treinamento = pd.read_excel('trident.xlsx', \"Treinamento\", sep=',')\n",
    "dados_Teste = pd.read_excel('Doritos.xlsx', \"Teste\", sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pegando os dados do treinamento\n",
    "dados_Treinamento = pd.read_excel('Doritos.xlsx', sheetname=\"Treinamento\")\n",
    "dados_Treinamento = dados_Treinamento.loc[:,[\"Treinamento\", \"Classificacao\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo tem-se a probabilidade da aba Treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.576667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.423333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classificacao\n",
       "i       0.576667\n",
       "r       0.423333"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuecounts_Treinamento = pd.DataFrame(dados_Treinamento.Classificacao.value_counts(True)) #probabilidade total irrelevante e neutro (relevante)\n",
    "probabilidade_total_irrelevante = valuecounts_Treinamento.Classificacao[0] #probabilidade total irrelevante\n",
    "\n",
    "probabilidade_total_neutra = valuecounts_Treinamento.Classificacao[1] #probabilidade total neutro (relevante)\n",
    "quantidade_de_neutros = len(dados_Treinamento[dados_Treinamento.Classificacao==\"r\"]) #Quantidade de neutros\n",
    "\n",
    "quantidade_de_irrelevantes = len(dados_Treinamento[dados_Treinamento.Classificacao==\"i\"]) #Quantidade de irrelevantes\n",
    "valuecounts_Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que a probabilidade da classifica√ß√£o \"i\" √© maior, na aba Treinamento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C√≥digo que gera um \"tweet\" √∫nico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#juntando tudo em um tweet gigante\n",
    "soma_Treinamento = np.sum(dados_Treinamento.Treinamento + \" \")\n",
    "soma_Treinamentoirrelevante = np.sum(dados_Treinamento[dados_Treinamento.Classificacao == \"i\"].Treinamento + \" \")\n",
    "soma_Treinamentoneutro = np.sum(dados_Treinamento[dados_Treinamento.Classificacao == \"r\"].Treinamento + \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C√≥digo que elimina alguns caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tirar todos os caracteres desnecess√°rios\n",
    "import string\n",
    "\n",
    "excluir= set(string.punctuation)\n",
    "def excluirpontos(soma):\n",
    "    soma = soma.split()\n",
    "    lista_palavrastweets = []\n",
    "    for r in soma:\n",
    "        for i in r:\n",
    "            if i in excluir:\n",
    "                r=r.replace(i, '')\n",
    "        lista_palavrastweets.append(r)\n",
    "    return lista_palavrastweets\n",
    "\n",
    "treinamentototal = excluirpontos(soma_Treinamento)\n",
    "treinamentoir = excluirpontos(soma_Treinamentoirrelevante)\n",
    "treinamentone = excluirpontos(soma_Treinamentoneutro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma√ß√£o do \"Tweet gigante(√∫nico)\" em uma Serie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tweet gigante virando uma Series (tabela)\n",
    "treinamentototal= pd.Series(treinamentototal)\n",
    "valuecounts_treinamentototal= treinamentototal.value_counts()\n",
    "\n",
    "treinamentoir= pd.Series(treinamentoir)\n",
    "valuecounts_treinamentoir= treinamentoir.value_counts()\n",
    "\n",
    "treinamentone= pd.Series(treinamentone)\n",
    "valuecounts_treinamentone= treinamentone.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a Probabilidade das palavras Irrelevantes e das palavras Neutras(Relevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[doritos           0.049636\n",
      "de                0.022313\n",
      "eu                0.017760\n",
      "o                 0.017760\n",
      "que               0.015938\n",
      "e                 0.015938\n",
      "a                 0.014572\n",
      "um                0.013206\n",
      "do                0.010018\n",
      "rt                0.009107\n",
      "√©                 0.008197\n",
      "minha             0.007286\n",
      "n√£o               0.006831\n",
      "no                0.006831\n",
      "na                0.006375\n",
      "pq                0.006375\n",
      "as                0.005920\n",
      "pra               0.005920\n",
      "me                0.005920\n",
      "meu               0.005464\n",
      "dededoritos       0.005464\n",
      "mas               0.005464\n",
      "vou               0.005009\n",
      "q                 0.005009\n",
      "doritosmx         0.005009\n",
      "vai               0.005009\n",
      "em                0.004554\n",
      "se                0.004554\n",
      "uma               0.004554\n",
      "vc                0.004098\n",
      "                    ...   \n",
      "lingua            0.000911\n",
      "biscoito          0.000911\n",
      "deus              0.000911\n",
      "inc√≥gnita         0.000911\n",
      "tengo             0.000911\n",
      "limpar            0.000911\n",
      "h√°                0.000911\n",
      "padaria           0.000911\n",
      "imbicar           0.000911\n",
      "cura              0.000911\n",
      "ngn               0.000911\n",
      "achava            0.000911\n",
      "p√°                0.000911\n",
      "quiser            0.000911\n",
      "chei              0.000911\n",
      "ver               0.000911\n",
      "gigante           0.000911\n",
      "caroldellac       0.000911\n",
      "sexta             0.000911\n",
      "ouvindo           0.000911\n",
      "facada            0.000911\n",
      "perdendo          0.000911\n",
      "playlist          0.000911\n",
      "pessoas           0.000911\n",
      "tenhoüòëüòë           0.000911\n",
      "cereais           0.000911\n",
      "acabou            0.000911\n",
      "oliveiraclaram    0.000911\n",
      "meo               0.000911\n",
      "contas            0.000911\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "prob_palavras_ir= []\n",
    "prob_palavra= (valuecounts_treinamentoir + 1)/(len(valuecounts_treinamentototal) + len(valuecounts_treinamentoir))\n",
    "prob_palavras_ir.append(prob_palavra)\n",
    "print(prob_palavras_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[doritos        0.070407\n",
      "de             0.035754\n",
      "um             0.024752\n",
      "e              0.020902\n",
      "pra            0.020902\n",
      "comer          0.017602\n",
      "eu             0.015952\n",
      "com            0.014851\n",
      "que            0.011551\n",
      "o              0.011001\n",
      "rt             0.009901\n",
      "√©              0.009351\n",
      "vontade        0.009351\n",
      "queria         0.008801\n",
      "meu            0.008801\n",
      "ele            0.008251\n",
      "no             0.007701\n",
      "a              0.007151\n",
      "uma            0.006051\n",
      "vou            0.006051\n",
      "minha          0.006051\n",
      "coca           0.006051\n",
      "do             0.006051\n",
      "comprar        0.006051\n",
      "agora          0.005501\n",
      "mim            0.005501\n",
      "               0.005501\n",
      "da             0.004950\n",
      "comendo        0.004950\n",
      "me             0.004950\n",
      "                 ...   \n",
      "chocolate      0.001100\n",
      "nunca          0.001100\n",
      "frango         0.001100\n",
      "bag            0.001100\n",
      "perdi          0.001100\n",
      "luto           0.001100\n",
      "üòçüòçüòçüòçüòç          0.001100\n",
      "fumei          0.001100\n",
      "caralho        0.001100\n",
      "parar          0.001100\n",
      "tanta          0.001100\n",
      "mt             0.001100\n",
      "querem         0.001100\n",
      "yaasmim18      0.001100\n",
      "pequeno        0.001100\n",
      "m              0.001100\n",
      "creme          0.001100\n",
      "ta             0.001100\n",
      "cigarro        0.001100\n",
      "preocupa√ß√£o    0.001100\n",
      "üò©              0.001100\n",
      "existir        0.001100\n",
      "‚Ä∫              0.001100\n",
      "larisi         0.001100\n",
      "saud√°vel       0.001100\n",
      "mau            0.001100\n",
      "paguei         0.001100\n",
      "presunto       0.001100\n",
      "pegou          0.001100\n",
      "ti             0.001100\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "prob_palavras_ne= []\n",
    "prob_palavra2= (valuecounts_treinamentone + 1)/(len(valuecounts_treinamentototal) + len(valuecounts_treinamentone))\n",
    "prob_palavras_ne.append(prob_palavra2)\n",
    "print(prob_palavras_ne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando dados da aba Teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pegando os dados do teste\n",
    "dados_Teste = pd.read_excel('Doritos.xlsx', sheetname=\"Teste\")\n",
    "dados_Teste = dados_Teste.loc[:,[\"Teste\", \"Classificacao\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C√≥digo que elimina alguns caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista_teste = dados_Teste.Teste\n",
    "#tirando a pontuacao\n",
    "import string\n",
    "excluir= set(string.punctuation)\n",
    "\n",
    "def excluirpontos(soma):\n",
    "    lista_tweets_em_palavras=[]\n",
    "    for s in range(len(soma)):\n",
    "        frase = soma[s].split()\n",
    "        lista_palavras=[]\n",
    "        \n",
    "        for r in frase:\n",
    "            for l in r:\n",
    "                if l in excluir:\n",
    "                    r=r.replace(l,'')\n",
    "            \n",
    "            lista_palavras.append(r)\n",
    "        lista_tweets_em_palavras.append(lista_palavras)\n",
    "        \n",
    "    return lista_tweets_em_palavras\n",
    "\n",
    "lista_pal_tweets= excluirpontos(lista_teste)\n",
    "#lista_pal_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C√ÅLCULO DA PROBABILIDADE DO TWEET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcula probabilidade da frase - neutro ou relevante\n",
    "def prob(lista_tweets_inteiros,probabilidade_da_palavra,prob,tweets):\n",
    "    lista_probabilidades = []\n",
    "    for frase in lista_tweets_inteiros:\n",
    "        probabilidade_frase = mpmath.mpf(1.000)\n",
    "        for p in frase:\n",
    "            if p in probabilidade_da_palavra:\n",
    "                probabilidade_frase = probabilidade_frase * probabilidade_da_palavra[p] * prob\n",
    "            else:\n",
    "                probabilidade_frase = mpmath.mpf(1)/(tweets+len(treinamentototal.value_counts())) * probabilidade_frase * prob\n",
    "        lista_probabilidades.append(probabilidade_frase)\n",
    "    return lista_probabilidades\n",
    "\n",
    "#cria lista sem pontua√ß√£o\n",
    "lista_tweets_em_palavras = excluirpontos(lista_teste)\n",
    "#C√°lculo da probabilidade do tweet ser neutro\n",
    "teste_probabilidade_total_irrelevante  = prob(lista_tweets_em_palavras,prob_palavra,probabilidade_total_irrelevante ,quantidade_de_neutros)\n",
    "#C√°lculo da probabilidade do tweet ser relevante\n",
    "teste_probabilidade_total_neutra = prob(lista_tweets_em_palavras,prob_palavra2,probabilidade_total_neutra,quantidade_de_irrelevantes)\n",
    "\n",
    "\n",
    "#Compara as listas de probabilidade e devolve neutro ou relevante\n",
    "def Compara√ß√£o(teste_probabilidade_total_irrelevante,teste_probabilidade_total_neutra):\n",
    "    resposta = []\n",
    "    for i in range(len(teste_probabilidade_total_irrelevante)):\n",
    "        if teste_probabilidade_total_irrelevante[i] > teste_probabilidade_total_neutra[i]:\n",
    "            resposta.append('i')\n",
    "        elif teste_probabilidade_total_irrelevante[i] < teste_probabilidade_total_neutra[i]:\n",
    "            resposta.append('r')\n",
    "    return resposta\n",
    "\n",
    "\n",
    "#lista de respostas do aplicativo\n",
    "resposta_teste = Compara√ß√£o(teste_probabilidade_total_irrelevante,teste_probabilidade_total_neutra)\n",
    "\n",
    "len(resposta_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'twitters': lista_tweets_em_palavras, 'Classificacao': dados_Teste.Classificacao, 'respostas': resposta_teste}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabela_tweets_classificados = pd.DataFrame(data, columns = ['twitters','Classificacao','respostas'])\n",
    "#tabelaT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista_verificacao = []\n",
    "for i in range(len(resposta_teste)):\n",
    "    if dados_Teste.Classificacao[i] == resposta_teste[i]:\n",
    "        if resposta_teste[i] == 'i':\n",
    "            lista_verificacao.append('negativo verdadeiro')\n",
    "        elif resposta_teste[i] == 'r':\n",
    "            lista_verificacao.append('positivo verdadeiro')\n",
    "            \n",
    "    elif dados_Teste.Classificacao[i] != resposta_teste[i]:\n",
    "        if resposta_teste[i] == 'i':\n",
    "            lista_verificacao.append('negativo falso')\n",
    "        elif resposta_teste[i] == 'r':\n",
    "            lista_verificacao.append('positivo falso')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negativo verdadeiro    0.490\n",
       "negativo falso         0.290\n",
       "positivo verdadeiro    0.205\n",
       "positivo falso         0.015\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificacaoS = pd.Series(lista_verificacao)\n",
    "porcentagem = verificacaoS.value_counts(True)\n",
    "porcentagem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   Os resultados do teste com a planilha dos Doritos, mostram que a probabilidade de um twitter ser \n",
    "irrelevante √© muito grande, o que influencia nos resultados do classificador. A porcentagem\n",
    "de positivos falsos √© 0.015 por esse motivo. Esse resultado t√£o baixo tem rela√ß√£o com sarcasmos e duplos negativos, que\n",
    "n√£o s√£o corretamente interpretados pelo sistema,pelo fato de a forma√ß√£o da frase n√£o ser considerada na conta.\n",
    "\n",
    "   √â poss√≠vel expandir o projeto e pensar em reclama√ß√µes mais espec√≠ficas, como por exemplo, o mau cheiro do produto. Assim, √©\n",
    "poss√≠vel organizar melhor a base de dados e obter resultados mais precisos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
