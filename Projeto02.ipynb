{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 13/Set at√© √†s 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "At√© o dia 06 de Setembro √†s 23:59, o notebook e o xlsx devem estar no Github com as seguintes evid√™ncias: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste j√° classificado.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conex√£o com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que ser√£o utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados √© necess√°rio ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@rodrigo32798866***\n",
    "\n",
    "\n",
    "1. Caso ainda n√£o tenha uma: https://twitter.com/signup\n",
    "1. Depois √© necess√°rio registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote tamb√©m:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATEN√á√ÉO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele cont√©m as chaves necess√°rias para realizar as opera√ß√µes no twitter de forma autom√°tica e portanto √© equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as opera√ß√µes manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo n√£o precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @rodrigo32798866\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, n√£o haver√° uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'trident'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora voc√™ deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem √© relevante ou n√£o.<br /> \n",
    "N√£o se esque√ßa de colocar um nome para a coluna na c√©lula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu c√≥digo abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpmath import mpf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "#dados_Treinamento = pd.read_excel('trident.xlsx', \"Treinamento\", sep=',')\n",
    "dados_Teste = pd.read_excel('trident.xlsx', \"Teste\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegando os dados do treinamento\n",
    "dados_Treinamento = pd.read_excel('trident.xlsx', sheetname=\"Treinamento\")\n",
    "dados_Treinamento = dados_Treinamento.loc[:,[\"Treinamento\", \"sentimento\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidades Treinamento relevante\n",
    "# valuecounts_Treinamento.loc[\"neutro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade Treinamento irrelevante\n",
    "# valuecounts_Treinamento.loc[\"irrelevante\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#juntando tudo em um tweet gigante\n",
    "soma_Treinamento = np.sum(dados_Treinamento.Treinamento + \" \")\n",
    "soma_Treinamentoirrelevante = np.sum(dados_Treinamento[dados_Treinamento.sentimento == \"irrelevante\"].Treinamento + \" \")\n",
    "soma_Treinamentoneutro = np.sum(dados_Treinamento[dados_Treinamento.sentimento == \"neutro\"].Treinamento + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tirar toda os caracteres necessarios\n",
    "import string\n",
    "\n",
    "excluir= set(string.punctuation)\n",
    "def excluirpontos(soma):\n",
    "    soma = soma.split()\n",
    "    lista_palavrastweets = []\n",
    "    for r in soma:\n",
    "        for i in r:\n",
    "            if i in excluir:\n",
    "                r=r.replace(i, '')\n",
    "        lista_palavrastweets.append(r)\n",
    "    return lista_palavrastweets\n",
    "\n",
    "treinamentototal = excluirpontos(soma_Treinamento)\n",
    "treinamentoir = excluirpontos(soma_Treinamentoirrelevante)\n",
    "treinamentone = excluirpontos(soma_Treinamentoneutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinamentototal= pd.Series(treinamentototal)\n",
    "valuecounts_treinamentototal= treinamentototal.value_counts()\n",
    "\n",
    "treinamentoir= pd.Series(treinamentoir)\n",
    "valuecounts_treinamentoir= treinamentoir.value_counts()\n",
    "\n",
    "treinamentone= pd.Series(treinamentone)\n",
    "valuecounts_treinamentone= treinamentone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trident               0.071541\n",
      "rt                    0.034193\n",
      "um                    0.033666\n",
      "de                    0.033140\n",
      "e                     0.029984\n",
      "                      0.026302\n",
      "que                   0.025776\n",
      "na                    0.024724\n",
      "eu                    0.022094\n",
      "o                     0.019463\n",
      "a                     0.015781\n",
      "n√£o                   0.014729\n",
      "festa                 0.014203\n",
      "√©                     0.014203\n",
      "com                   0.013151\n",
      "tem                   0.013151\n",
      "no                    0.010521\n",
      "pra                   0.010521\n",
      "mavi                  0.010521\n",
      "braga18mavi           0.010521\n",
      "parte                 0.009995\n",
      "meu                   0.008943\n",
      "os                    0.008417\n",
      "mas                   0.007891\n",
      "por                   0.007365\n",
      "da                    0.007365\n",
      "me                    0.006839\n",
      "dos                   0.006839\n",
      "uma                   0.006839\n",
      "do                    0.006839\n",
      "                        ...   \n",
      "compramos             0.001052\n",
      "mal                   0.001052\n",
      "quanto                0.001052\n",
      "srs                   0.001052\n",
      "üï∫üôãüèæ‚Äç‚ôÇÔ∏èüáßüá∑              0.001052\n",
      "part                  0.001052\n",
      "deixada               0.001052\n",
      "favor                 0.001052\n",
      "fuzis                 0.001052\n",
      "fei                   0.001052\n",
      "httpstcohbkw2ywcqs    0.001052\n",
      "t√¥                    0.001052\n",
      "cainho                0.001052\n",
      "nosso                 0.001052\n",
      "escovar               0.001052\n",
      "cadernos              0.001052\n",
      "üòÇüòÇüëÄüòç‚ù§Ô∏è                0.001052\n",
      "mosquitos             0.001052\n",
      "tempero               0.001052\n",
      "rasicm                0.001052\n",
      "paro                  0.001052\n",
      "queria                0.001052\n",
      "durar                 0.001052\n",
      "fabi                  0.001052\n",
      "longe                 0.001052\n",
      "üëÄ‚ù§Ô∏èüòç                  0.001052\n",
      "fome                  0.001052\n",
      "ciaobartomeu          0.001052\n",
      "nas                   0.001052\n",
      "dan√ßarinos            0.001052\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "prob_palavras_ir= []\n",
    "prob_palavra= (valuecounts_treinamentoir + 1)/(len(valuecounts_treinamentototal) + len(valuecounts_treinamentoir))\n",
    "prob_palavras_ir.append(prob_palavra)\n",
    "print(prob_palavras_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trident               0.097262\n",
      "rt                    0.056196\n",
      "um                    0.044669\n",
      "√©                     0.033862\n",
      "tem                   0.033862\n",
      "que                   0.033141\n",
      "de                    0.030259\n",
      "n√£o                   0.029539\n",
      "no                    0.026657\n",
      "abrindo               0.024496\n",
      "amigos                0.024496\n",
      "meio                  0.024496\n",
      "dos                   0.024496\n",
      "igual                 0.023775\n",
      "ci√∫mes                0.023055\n",
      "fala                  0.023055\n",
      "mas                   0.023055\n",
      "vc                    0.020893\n",
      "eu                    0.018732\n",
      "hmdaoras              0.018732\n",
      "httpstcoq76wbpx3u1    0.018732\n",
      "e                     0.010807\n",
      "se                    0.010086\n",
      "zuadavida             0.010086\n",
      "por                   0.010086\n",
      "canela                0.009366\n",
      "quero                 0.009366\n",
      "quando                0.009366\n",
      "pegar                 0.008646\n",
      "olhando               0.007925\n",
      "                        ...   \n",
      "ganhei                0.001441\n",
      "tocops                0.001441\n",
      "love                  0.001441\n",
      "est√¥mago              0.001441\n",
      "mexerica              0.001441\n",
      "importantes           0.001441\n",
      "valda                 0.001441\n",
      "ou                    0.001441\n",
      "ai                    0.001441\n",
      "maior                 0.001441\n",
      "pastilhas             0.001441\n",
      "achar                 0.001441\n",
      "pqp                   0.001441\n",
      "pediam                0.001441\n",
      "acabei                0.001441\n",
      "kkkkk                 0.001441\n",
      "dinda                 0.001441\n",
      "todo                  0.001441\n",
      "bateu                 0.001441\n",
      "cheinha               0.001441\n",
      "vai                   0.001441\n",
      "gosta                 0.001441\n",
      "üôãüèº                    0.001441\n",
      "n                     0.001441\n",
      "aaaaa                 0.001441\n",
      "trouxe                0.001441\n",
      "nosmoke               0.001441\n",
      "cisma                 0.001441\n",
      "kkkkk‚ù§                0.001441\n",
      "                      0.001441\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "prob_palavras_ne= []\n",
    "prob_palavra2= (valuecounts_treinamentone + 1)/(len(valuecounts_treinamentototal) + len(valuecounts_treinamentone))\n",
    "prob_palavras_ne.append(prob_palavra2)\n",
    "print(prob_palavras_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pegando os dados do teste\n",
    "dados_Teste = pd.read_excel('trident.xlsx', sheetname=\"Teste\")\n",
    "dados_Teste = dados_Teste.loc[:,[\"Teste\", \"sentimento\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste = dados_Teste.Teste\n",
    "#tirando a pontuacao\n",
    "import string\n",
    "excluir= set(string.punctuation)\n",
    "\n",
    "def excluirpontos(soma):\n",
    "    lista_tweets_em_palavras=[]\n",
    "    for s in range(len(soma)):\n",
    "        frase = soma[s].split()\n",
    "        lista_palavras=[]\n",
    "        \n",
    "        for r in frase:\n",
    "            for l in r:\n",
    "                if l in excluir:\n",
    "                    r=r.replace(l,'')\n",
    "            \n",
    "            lista_palavras.append(r)\n",
    "        lista_tweets_em_palavras.append(lista_palavras)\n",
    "        \n",
    "    return lista_tweets_em_palavras\n",
    "\n",
    "lista_pal_tweets= excluirpontos(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob():\n",
    "    lista_probabilidades=[]\n",
    "    for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! explorer .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
